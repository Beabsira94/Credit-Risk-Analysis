{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WOE Binning and Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this stage we are going to perform WOE binning and Model training using Logistic Regression, Descision Trees(Random Forest Model) and Gradient Boosting Machine(GBM) models. We are going to start with WOE Bining first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Information Value (IV)**:\n",
    "  - IV measures the predictive power of a feature in relation to a binary target variable. It quantifies how well a feature separates the classes (e.g., default vs. non-default).\n",
    "  - IV is calculated based on the distribution of the feature values across the target classes and is particularly useful for binary classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of ScorecardPy\n",
    "\n",
    "**ScorecardPy** is a Python library designed for building credit scoring models. It provides tools and functions to help data scientists and analysts create, validate, and deploy scorecards, particularly in the context of binary classification problems, such as predicting loan defaults or credit risk.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "1. **Binning**:\n",
    "   - Automatically bins continuous variables into categories, which helps in transforming numerical data into a format suitable for scorecard modeling.\n",
    "\n",
    "2. **WoE (Weight of Evidence) Transformation**:\n",
    "   - Converts binned variables into Weight of Evidence, which is a common transformation used in credit scoring to quantify the predictive power of each category.\n",
    "\n",
    "3. **Scorecard Development**:\n",
    "   - Facilitates the creation of a scorecard by allowing users to define points for each feature based on their predictive power and importance.\n",
    "\n",
    "4. **Model Evaluation**:\n",
    "   - Provides tools for evaluating the performance of the scorecard through metrics such as KS statistics, AUC (Area Under the Curve), and confusion matrices.\n",
    "\n",
    "5. **Visualization**:\n",
    "   - Includes functions for visualizing the distribution of variables, the relationship between features and the target variable, and the overall performance of the scorecard.\n",
    "\n",
    "6. **Integration**:\n",
    "   - Can be easily integrated into existing data science workflows and can work with pandas DataFrames, making it user-friendly for those familiar with Python and data manipulation.\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "- **Credit Risk Assessment**: Building models to evaluate the creditworthiness of applicants.\n",
    "- **Fraud Detection**: Identifying potentially fraudulent transactions or behaviors.\n",
    "- **Customer Segmentation**: Analyzing customer data to inform marketing strategies or product offerings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scorecardpy as sc\n",
    "from monotonic_binning.monotonic_woe_binning import Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"../notebooks/data/df_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CustomerId', 'TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CurrencyCode', 'CountryCode', 'ProviderId', 'ProductId', 'ProductCategory', 'ChannelId', 'Value', 'TransactionStartTime', 'PricingStrategy', 'FraudResult', 'Transaction_Hour', 'Transaction_Day', 'Transaction_Month', 'Transaction_Year', 'Total_Transaction_Amount', 'Average_Transaction_Amount', 'Transaction_Count', 'Std_Transaction_Amount', 'TransactionDate', 'Recency', 'Frequency', 'Monetary', 'Size', 'Risk_Label']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating woe binning ...\n",
      "[INFO] converting into woe values ...\n",
      "Columns in woebin_ply_result: Index(['BatchId', 'Std_Transaction_Amount', 'Monetary', 'TransactionStartTime', 'Transaction_Count', 'Frequency', 'Transaction_Month', 'TransactionId', 'Size', 'ProductCategory', 'Risk_Label', 'CurrencyCode', 'CountryCode', 'FraudResult', 'Transaction_Hour', 'ProductId', 'CustomerId', 'ChannelId', 'SubscriptionId',\n",
      "       'PricingStrategy', 'Average_Transaction_Amount', 'Recency', 'Transaction_Day', 'Transaction_Year', 'Value', 'ProviderId', 'TransactionDate', 'AccountId', 'Total_Transaction_Amount_woe'],\n",
      "      dtype='object')\n",
      "[INFO] creating woe binning ...\n",
      "[INFO] converting into woe values ...\n",
      "Columns in woebin_ply_result: Index(['BatchId', 'Std_Transaction_Amount', 'Monetary', 'TransactionStartTime', 'Transaction_Count', 'Frequency', 'Transaction_Month', 'TransactionId', 'Size', 'ProductCategory', 'Risk_Label', 'CurrencyCode', 'CountryCode', 'FraudResult', 'Transaction_Hour', 'Total_Transaction_Amount', 'ProductId', 'CustomerId',\n",
      "       'ChannelId', 'SubscriptionId', 'PricingStrategy', 'Recency', 'Transaction_Day', 'WoE_Total_Transaction_Amount', 'Transaction_Year', 'Value', 'ProviderId', 'TransactionDate', 'AccountId', 'Average_Transaction_Amount_woe'],\n",
      "      dtype='object')\n",
      "[INFO] creating woe binning ...\n",
      "[INFO] converting into woe values ...\n",
      "Columns in woebin_ply_result: Index(['BatchId', 'Std_Transaction_Amount', 'Monetary', 'TransactionStartTime', 'Frequency', 'Transaction_Month', 'TransactionId', 'Size', 'ProductCategory', 'Risk_Label', 'CurrencyCode', 'CountryCode', 'FraudResult', 'Transaction_Hour', 'Total_Transaction_Amount', 'ProductId', 'CustomerId', 'ChannelId',\n",
      "       'SubscriptionId', 'PricingStrategy', 'Average_Transaction_Amount', 'Recency', 'Transaction_Day', 'WoE_Total_Transaction_Amount', 'Transaction_Year', 'Value', 'WoE_Average_Transaction_Amount', 'ProviderId', 'TransactionDate', 'AccountId', 'Transaction_Count_woe'],\n",
      "      dtype='object')\n",
      "[INFO] creating woe binning ...\n",
      "[INFO] converting into woe values ...\n",
      "Columns in woebin_ply_result: Index(['BatchId', 'Std_Transaction_Amount', 'Transaction_Count', 'Transaction_Month', 'Size', 'ProductCategory', 'Risk_Label', 'FraudResult', 'CustomerId', 'ChannelId', 'SubscriptionId', 'PricingStrategy', 'Average_Transaction_Amount', 'WoE_Total_Transaction_Amount', 'Transaction_Year', 'ProviderId', 'AccountId',\n",
      "       'Monetary', 'TransactionStartTime', 'Frequency', 'TransactionId', 'CurrencyCode', 'CountryCode', 'Transaction_Hour', 'Total_Transaction_Amount', 'ProductId', 'Transaction_Day', 'Value', 'WoE_Average_Transaction_Amount', 'TransactionDate', 'WoE_Transaction_Count', 'Recency_woe'],\n",
      "      dtype='object')\n",
      "[INFO] creating woe binning ...\n",
      "[INFO] converting into woe values ...\n",
      "Columns in woebin_ply_result: Index(['BatchId', 'Std_Transaction_Amount', 'Transaction_Count', 'Transaction_Month', 'Size', 'ProductCategory', 'Risk_Label', 'FraudResult', 'CustomerId', 'ChannelId', 'SubscriptionId', 'PricingStrategy', 'Average_Transaction_Amount', 'Recency', 'WoE_Total_Transaction_Amount', 'Transaction_Year', 'ProviderId',\n",
      "       'AccountId', 'Monetary', 'TransactionStartTime', 'TransactionId', 'WoE_Recency', 'CurrencyCode', 'CountryCode', 'Transaction_Hour', 'Total_Transaction_Amount', 'ProductId', 'Transaction_Day', 'Value', 'WoE_Average_Transaction_Amount', 'TransactionDate', 'WoE_Transaction_Count', 'Frequency_woe'],\n",
      "      dtype='object')\n",
      "[INFO] creating woe binning ...\n",
      "[INFO] converting into woe values ...\n",
      "Columns in woebin_ply_result: Index(['BatchId', 'Std_Transaction_Amount', 'Transaction_Count', 'Transaction_Month', 'Size', 'ProductCategory', 'Risk_Label', 'FraudResult', 'CustomerId', 'ChannelId', 'SubscriptionId', 'PricingStrategy', 'Average_Transaction_Amount', 'Recency', 'WoE_Total_Transaction_Amount', 'Transaction_Year', 'ProviderId',\n",
      "       'AccountId', 'TransactionStartTime', 'Frequency', 'TransactionId', 'WoE_Recency', 'CurrencyCode', 'CountryCode', 'Transaction_Hour', 'Total_Transaction_Amount', 'ProductId', 'Transaction_Day', 'Value', 'WoE_Average_Transaction_Amount', 'WoE_Frequency', 'TransactionDate', 'WoE_Transaction_Count',\n",
      "       'Monetary_woe'],\n",
      "      dtype='object')\n",
      "[INFO] creating woe binning ...\n",
      "[INFO] converting into woe values ...\n",
      "Columns in woebin_ply_result: Index(['BatchId', 'Std_Transaction_Amount', 'Transaction_Count', 'Transaction_Month', 'Size', 'ProductCategory', 'Risk_Label', 'FraudResult', 'CustomerId', 'ChannelId', 'SubscriptionId', 'PricingStrategy', 'Average_Transaction_Amount', 'Recency', 'WoE_Monetary', 'WoE_Total_Transaction_Amount', 'Transaction_Year',\n",
      "       'AccountId', 'Monetary', 'TransactionStartTime', 'Frequency', 'TransactionId', 'WoE_Recency', 'CurrencyCode', 'CountryCode', 'Transaction_Hour', 'Total_Transaction_Amount', 'ProductId', 'Transaction_Day', 'Value', 'WoE_Average_Transaction_Amount', 'WoE_Frequency', 'TransactionDate', 'WoE_Transaction_Count',\n",
      "       'ProviderId_woe'],\n",
      "      dtype='object')\n",
      "[INFO] creating woe binning ...\n",
      "[INFO] converting into woe values ...\n",
      "Columns in woebin_ply_result: Index(['BatchId', 'Std_Transaction_Amount', 'Transaction_Count', 'Transaction_Month', 'Size', 'ProductCategory', 'WoE_ProviderId', 'Risk_Label', 'FraudResult', 'CustomerId', 'ChannelId', 'SubscriptionId', 'PricingStrategy', 'Average_Transaction_Amount', 'Recency', 'WoE_Monetary', 'WoE_Total_Transaction_Amount',\n",
      "       'Transaction_Year', 'ProviderId', 'AccountId', 'Monetary', 'TransactionStartTime', 'Frequency', 'TransactionId', 'WoE_Recency', 'CurrencyCode', 'CountryCode', 'Transaction_Hour', 'Total_Transaction_Amount', 'Transaction_Day', 'Value', 'WoE_Average_Transaction_Amount', 'WoE_Frequency', 'TransactionDate',\n",
      "       'WoE_Transaction_Count', 'ProductId_woe'],\n",
      "      dtype='object')\n",
      "[INFO] creating woe binning ...\n",
      "[INFO] converting into woe values ...\n",
      "Columns in woebin_ply_result: Index(['BatchId', 'Std_Transaction_Amount', 'Transaction_Count', 'Transaction_Month', 'Size', 'WoE_ProviderId', 'Risk_Label', 'FraudResult', 'CustomerId', 'ChannelId', 'SubscriptionId', 'PricingStrategy', 'Average_Transaction_Amount', 'Recency', 'WoE_Monetary', 'WoE_Total_Transaction_Amount', 'Transaction_Year',\n",
      "       'ProviderId', 'AccountId', 'WoE_ProductId', 'Monetary', 'TransactionStartTime', 'Frequency', 'TransactionId', 'WoE_Recency', 'CurrencyCode', 'CountryCode', 'Transaction_Hour', 'Total_Transaction_Amount', 'ProductId', 'Transaction_Day', 'Value', 'WoE_Average_Transaction_Amount', 'WoE_Frequency',\n",
      "       'TransactionDate', 'WoE_Transaction_Count', 'ProductCategory_woe'],\n",
      "      dtype='object')\n",
      "[INFO] creating woe binning ...\n",
      "[INFO] converting into woe values ...\n",
      "Columns in woebin_ply_result: Index(['BatchId', 'Std_Transaction_Amount', 'Transaction_Count', 'Transaction_Month', 'Size', 'ProductCategory', 'WoE_ProviderId', 'Risk_Label', 'FraudResult', 'CustomerId', 'SubscriptionId', 'PricingStrategy', 'Average_Transaction_Amount', 'WoE_ProductCategory', 'Recency', 'WoE_Monetary',\n",
      "       'WoE_Total_Transaction_Amount', 'Transaction_Year', 'ProviderId', 'AccountId', 'WoE_ProductId', 'Monetary', 'TransactionStartTime', 'Frequency', 'TransactionId', 'WoE_Recency', 'CurrencyCode', 'CountryCode', 'Transaction_Hour', 'Total_Transaction_Amount', 'ProductId', 'Transaction_Day', 'Value',\n",
      "       'WoE_Average_Transaction_Amount', 'WoE_Frequency', 'TransactionDate', 'WoE_Transaction_Count', 'ChannelId_woe'],\n",
      "      dtype='object')\n",
      "        CustomerId        TransactionId        BatchId       AccountId       SubscriptionId CurrencyCode  CountryCode  ProviderId  ProductId  ProductCategory  ChannelId     Value TransactionStartTime  PricingStrategy  FraudResult  Transaction_Hour  Transaction_Day  Transaction_Month  Transaction_Year  \\\n",
      "0  CustomerId_4406  TransactionId_76871  BatchId_36123  AccountId_3957   SubscriptionId_887          UGX          256           6         10                0          3  0.142612      11/15/2018 2:18                2            0                 2               15                 11              2018   \n",
      "1  CustomerId_4406  TransactionId_73770  BatchId_15642  AccountId_4841  SubscriptionId_3829          UGX          256           4          6                2          2  0.002572      11/15/2018 2:19                2            0                 2               15                 11              2018   \n",
      "2  CustomerId_4683  TransactionId_26203  BatchId_53941  AccountId_4229   SubscriptionId_222          UGX          256           6          1                0          3  0.071163      11/15/2018 2:44                2            0                 2               15                 11              2018   \n",
      "3   CustomerId_988  TransactionId_28195  BatchId_38780  AccountId_4841  SubscriptionId_3829          UGX          256           4          6                2          2  0.091740      11/15/2018 3:34                2            0                 3               15                 11              2018   \n",
      "4  CustomerId_1432  TransactionId_23223  BatchId_25954  AccountId_1078  SubscriptionId_4238          UGX          256           6          3                0          3  0.285510      11/15/2018 3:35                2            0                 3               15                 11              2018   \n",
      "\n",
      "   Total_Transaction_Amount  Average_Transaction_Amount  Transaction_Count  Std_Transaction_Amount  TransactionDate  Recency  Frequency   Monetary      Size  Risk_Label  WoE_Total_Transaction_Amount  WoE_Average_Transaction_Amount  WoE_Transaction_Count  WoE_Recency  WoE_Frequency  WoE_Monetary  WoE_ProviderId  \\\n",
      "0                  0.076935                    0.130165                104             1010.755043  11/15/2018 2:18       86        104  13.537204  0.076935           1                      1.865802                        0.047411               2.649033     1.562772       2.649033      1.927046       -0.075664   \n",
      "1                  0.076935                    0.130165                104             1010.755043  11/15/2018 2:19       86        104  13.537204  0.076935           1                      1.865802                        0.047411               2.649033     1.562772       2.649033      1.927046       -0.107274   \n",
      "2                  0.000773                    0.068100                  2                0.000000  11/15/2018 2:44        9          2   0.136201  0.000773           0                     -2.835048                       -1.150494              -3.136512    -5.963818      -3.136512     -1.841596       -0.075664   \n",
      "3                  0.022953                    0.169432                 24             1257.497549  11/15/2018 3:34       79         24   4.066380  0.022953           0                     -2.835048                        0.818138               0.408960     0.241130       0.408960     -1.841596       -0.107274   \n",
      "4                  0.001567                    0.283154                  1             1141.677114  11/15/2018 3:35        0          1   0.283154  0.001567           0                     -2.835048                        0.818138              -3.136512    -5.963818      -3.136512     -1.841596       -0.075664   \n",
      "\n",
      "   WoE_ProductId  WoE_ProductCategory  WoE_ChannelId  \n",
      "0      -0.173354             0.042687       0.090902  \n",
      "1      -0.119779            -0.042965      -0.135535  \n",
      "2       0.117586             0.042687       0.090902  \n",
      "3      -0.119779            -0.042965      -0.135535  \n",
      "4       0.117586             0.042687       0.090902  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scorecardpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sample DataFrame (replace this with your actual DataFrame)\n",
    "# df = pd.read_csv(\"your_file.csv\")  # Uncomment this line to load your dataset\n",
    "\n",
    "# Convert 'Risk_Label' to binary format (1 for 'Good' and 0 for 'Bad')\n",
    "df['Risk_Label'] = df['Risk_Label'].map({'Good': 1, 'Bad': 0})\n",
    "\n",
    "# Define the columns to perform WoE binning on, including categorical variables\n",
    "columns_to_bin = [\n",
    "    'Total_Transaction_Amount',\n",
    "    'Average_Transaction_Amount',\n",
    "    'Transaction_Count',\n",
    "    'Recency',\n",
    "    'Frequency',\n",
    "    'Monetary',\n",
    "    'ProviderId',        # Added categorical variable\n",
    "    'ProductId',         # Added categorical variable\n",
    "    'ProductCategory',    # Added categorical variable\n",
    "    'ChannelId'          # Added categorical variable\n",
    "]\n",
    "\n",
    "# Calculate y_threshold (proportion of Good outcomes)\n",
    "y_threshold = df['Risk_Label'].mean()  # Proportion of Good (1) outcomes\n",
    "# Set p_threshold based on the proportion of Bad outcomes\n",
    "p_threshold = 1 - y_threshold  # Proportion of Bad instances\n",
    "\n",
    "# Optimal n_threshold can be determined by your domain knowledge or experimentation\n",
    "n_threshold = 10  # Number of bins\n",
    "\n",
    "# Perform WoE Binning for each column and merge the results\n",
    "for column in columns_to_bin:\n",
    "    # Perform WoE binning using scorecardpy's woebin function\n",
    "    binning_result = sc.woebin(df, y='Risk_Label', x=column, \n",
    "                                n_bin=n_threshold,  # Number of bins\n",
    "                                p=0.05)  # Optional: Minimum proportion of good/bad for a bin\n",
    "\n",
    "    # Create a new column for WoE values in df\n",
    "    woe_column_name = f'WoE_{column}'\n",
    "\n",
    "    # Use woebin_ply to get WoE values and inspect the resulting DataFrame\n",
    "    woebin_ply_result = sc.woebin_ply(df, binning_result)\n",
    "\n",
    "    # Print columns for debugging\n",
    "    print(\"Columns in woebin_ply_result:\", woebin_ply_result.columns)\n",
    "\n",
    "    # Map the WoE values back to the DataFrame using the correct column name\n",
    "    woe_value_column = f\"{column}_woe\"  # Check the naming convention for WoE values\n",
    "    if woe_value_column in woebin_ply_result.columns:\n",
    "        df[woe_column_name] = woebin_ply_result[woe_value_column]  # Extract the WoE values\n",
    "    else:\n",
    "        print(f\"Warning: '{woe_value_column}' not found in the result DataFrame for '{column}'.\")\n",
    "\n",
    "# Display the first few rows of the updated DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CustomerId         TransactionId         BatchId       AccountId       SubscriptionId CurrencyCode  CountryCode  ProviderId  ProductId  ProductCategory  ChannelId     Value TransactionStartTime  PricingStrategy  FraudResult  Transaction_Hour  Transaction_Day  Transaction_Month  Transaction_Year  \\\n",
      "0  CustomerId_4406   TransactionId_76871   BatchId_36123  AccountId_3957   SubscriptionId_887          UGX          256           6         10                0          3  0.142612      11/15/2018 2:18                2            0                 2               15                 11              2018   \n",
      "1  CustomerId_4406   TransactionId_73770   BatchId_15642  AccountId_4841  SubscriptionId_3829          UGX          256           4          6                2          2  0.002572      11/15/2018 2:19                2            0                 2               15                 11              2018   \n",
      "2  CustomerId_4683   TransactionId_26203   BatchId_53941  AccountId_4229   SubscriptionId_222          UGX          256           6          1                0          3  0.071163      11/15/2018 2:44                2            0                 2               15                 11              2018   \n",
      "3   CustomerId_988   TransactionId_28195   BatchId_38780  AccountId_4841  SubscriptionId_3829          UGX          256           4          6                2          2  0.091740      11/15/2018 3:34                2            0                 3               15                 11              2018   \n",
      "4  CustomerId_1432   TransactionId_23223   BatchId_25954  AccountId_1078  SubscriptionId_4238          UGX          256           6          3                0          3  0.285510      11/15/2018 3:35                2            0                 3               15                 11              2018   \n",
      "5  CustomerId_2858  TransactionId_100640   BatchId_38561  AccountId_4841  SubscriptionId_3829          UGX          256           4          6                2          2  0.071163      11/15/2018 3:45                2            0                 3               15                 11              2018   \n",
      "6   CustomerId_598   TransactionId_51905   BatchId_93774   AccountId_272  SubscriptionId_4731          UGX          256           6         10                0          3  0.071163      11/15/2018 4:14                2            0                 4               15                 11              2018   \n",
      "7  CustomerId_1053  TransactionId_130161   BatchId_82409   AccountId_710   SubscriptionId_920          UGX          256           1         15                2          3  0.085453      11/15/2018 4:31                2            0                 4               15                 11              2018   \n",
      "8  CustomerId_3052   TransactionId_51800  BatchId_112288  AccountId_2634  SubscriptionId_3511          UGX          256           6          3                0          3  0.126893      11/15/2018 4:32                2            0                 4               15                 11              2018   \n",
      "9  CustomerId_3052   TransactionId_33857  BatchId_126394  AccountId_4841  SubscriptionId_3829          UGX          256           4          6                2          2  0.005430      11/15/2018 4:32                2            0                 4               15                 11              2018   \n",
      "\n",
      "   Total_Transaction_Amount  Average_Transaction_Amount  Transaction_Count  Std_Transaction_Amount  TransactionDate  Recency  Frequency   Monetary      Size  Risk_Label  WoE_Total_Transaction_Amount  WoE_Average_Transaction_Amount  WoE_Transaction_Count  WoE_Recency  WoE_Frequency  WoE_Monetary  WoE_ProviderId  \\\n",
      "0                  0.076935                    0.130165                104             1010.755043  11/15/2018 2:18       86        104  13.537204  0.076935           1                      1.865802                        0.047411               2.649033     1.562772       2.649033      1.927046       -0.075664   \n",
      "1                  0.076935                    0.130165                104             1010.755043  11/15/2018 2:19       86        104  13.537204  0.076935           1                      1.865802                        0.047411               2.649033     1.562772       2.649033      1.927046       -0.107274   \n",
      "2                  0.000773                    0.068100                  2                0.000000  11/15/2018 2:44        9          2   0.136201  0.000773           0                     -2.835048                       -1.150494              -3.136512    -5.963818      -3.136512     -1.841596       -0.075664   \n",
      "3                  0.022953                    0.169432                 24             1257.497549  11/15/2018 3:34       79         24   4.066380  0.022953           0                     -2.835048                        0.818138               0.408960     0.241130       0.408960     -1.841596       -0.107274   \n",
      "4                  0.001567                    0.283154                  1             1141.677114  11/15/2018 3:35        0          1   0.283154  0.001567           0                     -2.835048                        0.818138              -3.136512    -5.963818      -3.136512     -1.841596       -0.075664   \n",
      "5                  0.035514                    0.317563                 20             1927.679270  11/15/2018 3:45       85         20   6.351254  0.035514           1                      1.865802                       -0.193516               0.408960     1.562772       0.408960      1.927046       -0.107274   \n",
      "6                  0.001043                    0.060454                  3              283.783955  11/15/2018 4:14        1          3   0.181362  0.001043           0                     -2.835048                       -1.150494              -3.136512    -5.963818      -3.136512     -1.841596       -0.075664   \n",
      "7                  0.010935                    0.279304                  7             1907.314642  11/15/2018 4:31        1          7   1.955125  0.010935           0                     -2.835048                        0.818138              -3.136512    -5.963818      -3.136512     -1.841596        0.148476   \n",
      "8                  0.008769                    0.128793                 12              644.869026  11/15/2018 4:32       28         12   1.545520  0.008769           0                     -2.835048                        0.047411              -3.136512     0.241130      -3.136512     -1.841596       -0.075664   \n",
      "9                  0.008769                    0.128793                 12              644.869026  11/15/2018 4:32       28         12   1.545520  0.008769           0                     -2.835048                        0.047411              -3.136512     0.241130      -3.136512     -1.841596       -0.107274   \n",
      "\n",
      "   WoE_ProductId  WoE_ProductCategory  WoE_ChannelId  \n",
      "0      -0.173354             0.042687       0.090902  \n",
      "1      -0.119779            -0.042965      -0.135535  \n",
      "2       0.117586             0.042687       0.090902  \n",
      "3      -0.119779            -0.042965      -0.135535  \n",
      "4       0.117586             0.042687       0.090902  \n",
      "5      -0.119779            -0.042965      -0.135535  \n",
      "6      -0.173354             0.042687       0.090902  \n",
      "7       0.241229            -0.042965       0.090902  \n",
      "8       0.117586             0.042687       0.090902  \n",
      "9      -0.119779            -0.042965      -0.135535  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the updated DataFrame\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as 'final_woe_bin.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "df.to_csv('../notebooks/data/final_woe_bin.csv', index=False)\n",
    "\n",
    "print(\"DataFrame saved as 'final_woe_bin.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training And Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this phase we are going to train the aformentioned models and evaluate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Accuracy  Precision    Recall  F1 Score   ROC AUC\n",
      "Logistic Regression  0.784734   0.747896  0.753365  0.750621  0.886593\n",
      "Random Forest        1.000000   1.000000  1.000000  1.000000  1.000000\n",
      "Gradient Boosting    1.000000   1.000000  1.000000  1.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from monotonic_binning.monotonic_woe_binning import Binning\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load your DataFrame\n",
    "df = pd.read_csv(\"../notebooks/data/df_merged.csv\")\n",
    "\n",
    "# Convert Risk_Label to binary format (1 for 'Good' and 0 for 'Bad')\n",
    "df['Risk_Label'] = df['Risk_Label'].map({'Good': 1, 'Bad': 0})\n",
    "\n",
    "# Define features and target variable\n",
    "X = df[['Recency', 'Frequency', 'Monetary']]\n",
    "y = df['Risk_Label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Selection and Training\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning setup\n",
    "param_grid = {\n",
    "    'Logistic Regression': {'C': [0.01, 0.1, 1, 10]},\n",
    "    'Random Forest': {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]},\n",
    "    'Gradient Boosting': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2]}\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "performance = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Hyperparameter tuning\n",
    "    grid_search = GridSearchCV(model, param_grid[model_name], cv=5, scoring='roc_auc')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best model after tuning\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_pred_proba = best_model.predict_proba(X_test)[:, 1]  # Get probability of positive class\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    # Store performance\n",
    "    performance[model_name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'ROC AUC': roc_auc\n",
    "    }\n",
    "\n",
    "    # Create the Models directory if it doesn't exist\n",
    "    os.makedirs('Models', exist_ok=True)\n",
    "\n",
    "    # Save the model\n",
    "    with open(f'Models/{model_name.replace(\" \", \"_\")}.pkl', 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "\n",
    "# Display performance metrics\n",
    "performance_df = pd.DataFrame(performance).T\n",
    "print(performance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "### Interpretation of Model Performance\n",
    "\n",
    "The results of the modeling task reveal a clear distinction in the performance metrics of the three models employed to predict credit risk based on the features of Recency, Frequency, and Monetary values. The **Logistic Regression** model achieved an accuracy of approximately **78.47%**, with precision, recall, and F1 scores reflecting a balanced performance. The **ROC AUC** of **0.887** indicates a good ability to distinguish between the positive and negative classes. This suggests that while the Logistic Regression model performs reasonably well, it may not capture the complexity of the data as effectively as the more sophisticated ensemble methods used.\n",
    "\n",
    "In stark contrast, both the **Random Forest** and **Gradient Boosting** models achieved perfect scores across all metrics, including an accuracy of **100%** and an ROC AUC of **1.000**. While these results appear promising, they raise concerns about potential overfitting. The extreme performance of these models suggests they may have learned noise or specific patterns from the training data that do not generalize well to unseen data. Such overfitting could lead to unreliable predictions in a real-world scenario, where the model may fail to maintain its accuracy on new, unseen instances. As a result, while the Random Forest and Gradient Boosting models showcase exceptional metrics, caution must be exercised when interpreting these results due to the likelihood of overfitting. Balancing model complexity with generalizability will be essential for developing a robust credit scoring system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
